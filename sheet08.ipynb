{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea953ba3",
   "metadata": {},
   "source": [
    "# Sheet 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdef980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab8718",
   "metadata": {},
   "source": [
    "## 1) Anomaly detection for Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data to folder data04\n",
    "# this might take some time (50MB)\n",
    "# you can also do this manually (download + unpack zip)\n",
    "#import wget\n",
    "#from zipfile import ZipFile\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#DESTINATION = \"data06\"\n",
    "#url = \"https://www.thphys.uni-heidelberg.de/~plehn/pics/\"\n",
    "#filename = \"toptagging-short.zip\"\n",
    "#url = url + filename\n",
    "\n",
    "#os.makedirs(DESTINATION, exist_ok=True)\n",
    "#os.chdir(DESTINATION)\n",
    "#wget.download(url, filename)\n",
    "#with ZipFile(filename, \"r\") as zip_ref:\n",
    "#    for file in tqdm(iterable=zip_ref.namelist(), total=len(zip_ref.namelist())):\n",
    "#        zip_ref.extract(member=file)\n",
    "#os.chdir(\"..\")\n",
    "%ls data06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f995bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "X_train = np.load( \"data06/toptagging-short/x_train_short.npy\")\n",
    "y_train = np.load( \"data06/toptagging-short/y_train_short.npy\")\n",
    "X_test = np.load( \"data06/toptagging-short/x_test_short.npy\")\n",
    "y_test = np.load( \"data06/toptagging-short/y_test_short.npy\")\n",
    "X_val = np.load( \"data06/toptagging-short/x_val_short.npy\")\n",
    "y_val = np.load( \"data06/toptagging-short/y_val_short.npy\")\n",
    "\n",
    "print(f\"train data shape: {X_train.shape}\")\n",
    "print(f\"train labels shape: {y_train.shape}\")\n",
    "print(f\"test data shape: {X_test.shape}\")\n",
    "print(f\"test labels shape: {y_test.shape}\")\n",
    "print(f\"val data shape: {X_val.shape}\")\n",
    "print(f\"val labels shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea8ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some initial settings\n",
    "__n_warning__ = 0.7\n",
    "n_shift_phi, n_shift_eta = 0, 0\n",
    "\n",
    "# Grid settings\n",
    "xpixels = np.arange(-2.6, 2.6, 0.029)\n",
    "ypixels = np.arange(-np.pi, np.pi, 0.035)\n",
    "\n",
    "# Calculate the pseudorapidity of pixel entries\n",
    "def eta (pT, pz):\n",
    "    small = 1e-10\n",
    "    small_pT = (np.abs(pT) < small)\n",
    "    small_pz = (np.abs(pz) < small)\n",
    "    not_small = ~(small_pT | small_pz)\n",
    "    theta = np.arctan(pT[not_small]/pz[not_small])\n",
    "    theta[theta < 0] += np.pi\n",
    "    etas = np.zeros_like(pT)\n",
    "    etas[small_pz] = 0\n",
    "    etas[small_pT] = 1e-10\n",
    "    etas[not_small] = np.log(np.tan(theta/2))\n",
    "    return etas\n",
    "\n",
    "# Calculate the azimuthal angle of pixel entries\n",
    "def phi (px, py):\n",
    "    \"\"\"\n",
    "    phis are returned in rad., np.arctan(0,0)=0 -> zero constituents set to -np.pi\n",
    "    \"\"\"\n",
    "    phis = np.arctan2(py,px)\n",
    "    phis[phis < 0] += 2*np.pi\n",
    "    phis[phis > 2*np.pi] -= 2*np.pi\n",
    "    phis = phis - np.pi \n",
    "    return phis\n",
    "\n",
    "# function to calculate masses\n",
    "def mass (E,px,py,pz):\n",
    "    mass = np.sqrt(np.maximum(0.,E**2-px**2-py**2-pz**2))\n",
    "    return mass\n",
    "\n",
    "# function to return the image momenta for centroid and principal axis\n",
    "def img_mom (x, y, weights, x_power, y_power):\n",
    "    return ((x**x_power)*(y**y_power)*weights).sum()\n",
    "\n",
    "# returns the jet image\n",
    "def orig_image (etas, phis, es):\n",
    "    \"\"\"\n",
    "    Gives the value on grid with minimal distance,\n",
    "    eg. for xpixel = (0,1,2,3,..) eta=1.3 -> xpixel=1, eta=1.6 ->xpixel=2\n",
    "    \"\"\"\n",
    "    z = np.zeros((etas.shape[0],len(xpixels),len(ypixels)))\n",
    "    in_grid = ~((etas < xpixels[0]) | (etas > xpixels[-1]) | (phis < ypixels[0]) | (phis > ypixels[-1]))\n",
    "    xcoords = np.argmin(np.abs(etas[:,None,:] - xpixels[None,:,None]),axis=1)\n",
    "    ycoords = np.argmin(np.abs(phis[:,None,:] - ypixels[None,:,None]),axis=1)\n",
    "    ncoords = np.repeat(np.arange(etas.shape[0])[:,None],etas.shape[1],axis=1)\n",
    "    z[ncoords[in_grid],ycoords[in_grid],xcoords[in_grid]] = es[in_grid]\n",
    "    return z\n",
    "\n",
    "# preprocess the jet\n",
    "def preprocessing( x ,y, weights, rotate=True, flip=True ):\n",
    "    \"\"\"\n",
    "    (x,y) are the coordinates and weights the corresponding values, shifts\n",
    "    centroid to origin, rotates image, so that principal axis is vertical,\n",
    "    flips image, so that most weights lay in (x<0, y>0)-plane.\n",
    "    Method for calculating principal axis (similar to tensor of inertia):\n",
    "    https://en.wikipedia.org/wiki/Image_moment\n",
    "    here: y=phi, phi has modulo 2*np.pi but it's not been taken care of hear,\n",
    "    so possible issues with calculating the centroid\n",
    "    -> pre-shifting of events outside of this function solves the problem\n",
    "    for iamge-data with Delta_phi < 2*np.pi\n",
    "    \"\"\"\n",
    "\n",
    "    # Shift\n",
    "    x_centroid = img_mom(x, y, weights, 1, 0) / weights.sum()\n",
    "    y_centroid = img_mom(x, y, weights, 0, 1)/ weights.sum()\n",
    "    x = x - x_centroid\n",
    "    y = y - y_centroid\n",
    "\n",
    "    # Check if shifting worked, there can be problems with modulo variables like phi (y)\n",
    "    # x and y are sorted after highest weight, 0-comp. gives hottest event\n",
    "    # for Jet-like Images Centroid should be close to hottest constituen (pT-sorted arrays)  \n",
    "    global n_shift_phi\n",
    "    global n_shift_eta\n",
    "    if np.abs(x[0]) > __n_warning__:\n",
    "        n_shift_eta += 1  \n",
    "    if np.abs(y[0]) > __n_warning__:\n",
    "        n_shift_phi += 1       \n",
    "\n",
    "    if rotate:\n",
    "        #Ccovariant matrix, eigenvectors corr. to principal axis\n",
    "        u11 = img_mom(x, y, weights, 1, 1) / weights.sum()\n",
    "        u20 = img_mom(x, y, weights, 2, 0) / weights.sum()\n",
    "        u02 = img_mom(x, y, weights, 0, 2) / weights.sum()\n",
    "        cov = np.array([[u20, u11], [u11, u02]])\n",
    "\n",
    "        # Eigenvalues and eigenvectors of covariant matrix\n",
    "        evals, evecs = np.linalg.eig(cov)\n",
    "\n",
    "        # Sorts the eigenvalues, v1, [::-1] turns array around, \n",
    "        sort_indices = np.argsort(evals)[::-1]\n",
    "        e_1 = evecs[:, sort_indices[0]]  # Eigenvector with largest eigenvalue\n",
    "        e_2 = evecs[:, sort_indices[1]]\n",
    "\n",
    "        # Theta to x_asix, arctan2 gives correct angle\n",
    "        theta = np.arctan2(e_1[0], e_1[1])\n",
    "  \n",
    "        # Rotation, so that princple axis is vertical\n",
    "        # anti-clockwise rotation matrix\n",
    "        rotation = np.matrix([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "        transformed_mat = rotation * np.stack([x,y])\n",
    "        x_rot, y_rot = transformed_mat.A\n",
    "    else: \n",
    "        x_rot, y_rot = x, y\n",
    "  \n",
    "    # Flipping\n",
    "    n_flips = 0\n",
    "    if flip:\n",
    "        if weights[x_rot<0.].sum() < weights[x_rot>0.].sum():\n",
    "            x_rot = -x_rot\n",
    "            n_flips  += 1\n",
    "        if weights[y_rot<0.].sum() > weights[y_rot>0.].sum():\n",
    "            y_rot = -y_rot\n",
    "            n_flips += 1\n",
    "            \n",
    "    return x_rot, y_rot\n",
    "\n",
    "\n",
    "# function to convert the jet to an image\n",
    "def constit_to_img( jets, n_constit, norm, rotate, flip ):\n",
    "    \n",
    "    print( \"Crop constituents\" )\n",
    "    jets = jets[:,0:n_constit,:]\n",
    "    \n",
    "    print( \"Calculating pT\" )\n",
    "    E     = jets[:,:,0]\n",
    "    pxs   = jets[:,:,1]\n",
    "    pys   = jets[:,:,2]\n",
    "    pzs   = jets[:,:,3]\n",
    "    pT    = np.sqrt(pxs**2+pys**2)\n",
    "    \n",
    "    print( \"Calculating eta\" )\n",
    "    etas  = eta(pT,pzs)\n",
    "    \n",
    "    print( \"Calculating phi\" )\n",
    "    phis  = phi(pxs,pys)\n",
    "    \n",
    "    print( \"Calculating the mass\" )\n",
    "    E_tot = E.sum(axis=1)\n",
    "    px_tot = pxs.sum(axis=1)\n",
    "    py_tot = pys.sum(axis=1)\n",
    "    pz_tot = pzs.sum(axis=1)\n",
    "    j_mass = mass(E_tot, px_tot, py_tot, pz_tot)\n",
    "    \n",
    "    print( \"Pre-shifting the phis\" )\n",
    "    phis = (phis.T - phis[:,0]).T\n",
    "    phis[phis < -np.pi] += 2*np.pi\n",
    "    phis[phis > np.pi] -= 2*np.pi\n",
    "    \n",
    "    print( \"Using pT as weight\" )\n",
    "    weights = pT\n",
    "    \n",
    "    print( \"Preprocessing\" )\n",
    "    \n",
    "    for i in range( np.shape(etas)[0] ):\n",
    "        etas[i,:], phis[i,:] = preprocessing( etas[i,:], phis[i,:], weights[i,:], rotate, flip )\n",
    "    \n",
    "    print( \"Creating images\" )\n",
    "    z_ori = orig_image(etas, phis, weights)\n",
    "    \n",
    "    #return z_ori\n",
    "        \n",
    "    print( \"Cropping and normalising\" )\n",
    "    n_crop = 40\n",
    "    z_new = np.zeros( (z_ori.shape[0],n_crop, n_crop) )\n",
    "    for i in range(z_ori.shape[0]):\n",
    "        Npix = z_ori[i,:,:].shape\n",
    "        z_new[i,:,:] = z_ori[i, int(Npix[0]/2-n_crop/2) : int(Npix[0]/2+n_crop/2), int(Npix[1]/2-n_crop/2) : int(Npix[1]/2+n_crop/2) ]\n",
    "        if norm:\n",
    "            z_sum = z_new[i,:,:].sum()\n",
    "            if z_sum != 0.:\n",
    "                z_new[i,:,:] = z_new[i,:,:]/z_sum\n",
    "    \n",
    "    print( \"Reshaping\" )\n",
    "    z_out = z_new.reshape( (z_new.shape[0],-1) ).reshape(-1, 1, 40,40)\n",
    "    \n",
    "    return z_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b84857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_manipulator( torch.utils.data.Dataset ):\n",
    "    \n",
    "    def __init__( self, imgs, labels ):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b149fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing data\n",
    "z_train = constit_to_img( X_train, 50, True, True, True )\n",
    "z_val = constit_to_img( X_val, 50, True, True, True )\n",
    "z_test = constit_to_img( X_test, 50, True, True, True )\n",
    "print(z_train.shape)\n",
    "print(z_val.shape)\n",
    "print(z_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76355415",
   "metadata": {},
   "source": [
    "(a) Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf633ebf",
   "metadata": {},
   "source": [
    "The Autoencoder below is built out of two different Multi Layer Perceptrons, the first one goes from 1600 to 10 neurons, while the second one expands the representation obtained from the other section growing back to the original size of 1600 pixels.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, inner_rep_size=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1600, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, inner_rep_size),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(inner_rep_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1600),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shape = x.shape\n",
    "        x = x.flatten(1)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f67e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train autoencoder function used to train the autoencoder model\n",
    "def train_autoencoder( model, dataloader, epochs = 10, learning_rate = 0.001 ):\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam( model.parameters(), lr = learning_rate )\n",
    "    losses = []\n",
    "\n",
    "    for i in tqdm( range( epochs ) ):\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_function( outputs, x )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append( loss.item() )\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3b354",
   "metadata": {},
   "source": [
    "(b) In this section we train the autoencoder just on QCD jets and the later we will show how the system is not quite able to recognize TOP jets in a test environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9eefb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the QCD training data\n",
    "qcd_train = z_train[ np.where( y_train == 0 ) ]\n",
    "qcd_train_tensor = torch.tensor( qcd_train.astype( np.float32 ) )\n",
    "\n",
    "# Generate the QCD training labels (we will not use these but we need them for the dataloader)\n",
    "qcd_train_labels = y_train[ np.where( y_train == 0 ) ]\n",
    "qcd_train_labels = torch.Tensor( qcd_train_labels.astype( np.float32 ) ).unsqueeze( -1 )\n",
    "\n",
    "# Building the dataloader\n",
    "train_dataset = dataset_manipulator( qcd_train_tensor, qcd_train_labels )\n",
    "trn_dataloader = torch.utils.data.DataLoader( train_dataset, batch_size=30, shuffle=True )\n",
    "\n",
    "model = Autoencoder(20)\n",
    "epochs = 10\n",
    "losses = train_autoencoder( model, trn_dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( np.linspace(0,epochs,len(losses)),losses, c=\"darkcyan\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462089c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autoencoder function used to test the autoencoder model\n",
    "def test_autoencoder( model, dataloader ):\n",
    "    loss_function = nn.MSELoss()\n",
    "    losses = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        outputs = model(x)\n",
    "        loss = loss_function( outputs, x )\n",
    "        losses.append( loss.item() )\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98916482",
   "metadata": {},
   "source": [
    "In this section we will put the autoencoder trained just on QCD jets against a dataset containing both QCD and TOP jets, the idea is to prove that the model fails at representing correctly all of the features of a TOP jet coming out of the latent space. We used bigger batches to save some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jets = torch.tensor(z_test.astype(np.float32))\n",
    "\n",
    "\n",
    "test_jets_labels = torch.Tensor( y_test.astype(np.float32) ).unsqueeze( -1 )\n",
    "\n",
    "test_dataset = dataset_manipulator( test_jets, test_jets_labels )\n",
    "tst_dataloader = torch.utils.data.DataLoader( test_dataset, batch_size=30, shuffle=False )\n",
    "\n",
    "losses = test_autoencoder(model, tst_dataloader)\n",
    "plt.plot(losses, c=\"darkcyan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed20835",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55228221",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_jets_val = torch.tensor(z_val.astype(np.float32))\n",
    "top_jets_original = z_val[ np.where(y_val==1) ]\n",
    "qcd_jets_original = z_val[ np.where(y_val==0) ]\n",
    "\n",
    "pred = model(qcd_jets_val)\n",
    "pred = pred.detach().numpy()\n",
    "\n",
    "reconstructed_top_jets = pred[ np.where(y_val==1) ]\n",
    "reconstructed_qcd_jets = pred[ np.where(y_val==0) ]\n",
    "\n",
    "fig, axs = plt.subplots( 4, 4, figsize=(18,18) )\n",
    "\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow( qcd_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[0, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[0, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[0, i].set_title(f\"Original QCD jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[1, i].imshow( reconstructed_qcd_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[1, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[1, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[1, i].set_title(\"Corresponding reconstructed QCD jet\", fontsize=10)\n",
    "\n",
    "    axs[2, i].imshow( top_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[2, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[2, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[2, i].set_title(f\"Original TOP jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[3, i].imshow( reconstructed_top_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[3, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[3, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[3, i].set_title(\"Corresponding reconstructed TOP jet\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d445d2",
   "metadata": {},
   "source": [
    "It's not really easy to come to conclusions on which one is the best stepped down representation overall, we can say for certain that when it comes to the reconstruction of top jets the amount of noise for each one of the images is really important and is, probably, sign of a struggle and inability to really get hold of what the features are inside the image.<br> \n",
    "Some noise is still present in some of the QCD jets reconstructions but it's harder to notice and it's apparent that the autoencoder was able to clearly grasp where the kernel of the image is positioned and which are the most important features in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( 1, 2, figsize=(9, 5) )\n",
    "axs[0].imshow(z_val.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[0].set_xlabel( \"$\\eta$\" )\n",
    "axs[0].set_ylabel( \"$\\phi$\" )\n",
    "axs[0].set_title(f\"Original dataset average distribution\", fontsize=10)\n",
    "\n",
    "axs[1].imshow(pred.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[1].set_xlabel( \"$\\eta$\" )\n",
    "axs[1].set_ylabel( \"$\\phi$\" )\n",
    "axs[1].set_title(f\"Reconstructed dataset average distribution\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed1e62",
   "metadata": {},
   "source": [
    "We can see even better how information was removed during the reconstruction process thanks to a plot of the average distribution of the images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff299b9",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47ca4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize pixel-wise MSE, plot ROC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "qcd_mse = []\n",
    "top_mse = []\n",
    "\n",
    "for i in range(qcd_jets_original.shape[0]):\n",
    "    qcd_mse.append(mean_squared_error(qcd_jets_original[i][0], reconstructed_qcd_jets[i][0]))\n",
    "for i in range(top_jets_original.shape[0]):    \n",
    "    top_mse.append(mean_squared_error(top_jets_original[i][0], reconstructed_top_jets[i][0]))\n",
    "\n",
    "average_qcd_mse = np.mean(qcd_mse)\n",
    "average_top_mse = np.mean(top_mse)\n",
    "\n",
    "plt.scatter(range(4), qcd_mse[0:4], marker=\".\", c=\"red\", label=\"QCD MSE\")\n",
    "plt.scatter(range(5, 9), top_mse[0:4], marker=\".\", c=\"blue\", label=\"TOP MSE\")\n",
    "\n",
    "plt.axhline(y=average_qcd_mse, color=\"red\", linestyle=\"--\", label=\"avg QCD MSE\")\n",
    "plt.axhline(y=average_top_mse, color=\"blue\", linestyle=\"--\", label=\"avg TOP MSE\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Jet\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638dd60",
   "metadata": {},
   "source": [
    "Using the MSE to check the error comparing each image with the reconstructed jet we get (predictably) a higher error for top jets, if compared with QCD jets.<br>\n",
    "Moreover we thought it could be usefult to show and plot the respective averages, and once again we can show that, on average, the mean squared error computed on the reconstructed images for the QCD jets is lower than the average error for the top jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b43d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve , roc_auc_score\n",
    "\n",
    "qcd_mse = np.array(qcd_mse)\n",
    "top_mse = np.array(top_mse)\n",
    "jets_mse = np.concatenate((qcd_mse,top_mse), axis=None)\n",
    "jets_mse.size\n",
    "\n",
    "label_jets = []\n",
    "\n",
    "for i in range(qcd_mse.size):\n",
    "    label_jets.append(0)\n",
    "\n",
    "for i in range(top_mse.size):\n",
    "    label_jets.append(1)\n",
    "\n",
    "label_jets = np.array(label_jets)\n",
    "\n",
    "rnd_class = np.linspace(0, 1, 100)\n",
    "fpr, tpr, th = roc_curve(label_jets,jets_mse)\n",
    "auc_score = roc_auc_score(label_jets,jets_mse)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('Specificity (False Positive) [%]')\n",
    "plt.ylabel('Sensitivity (True Positive) [%]')\n",
    "plt.grid()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}' )\n",
    "plt.plot(rnd_class, rnd_class, '--', label='Rnd classifier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8fbac",
   "metadata": {},
   "source": [
    "A test statistic built in this way performs good in distinguish TOP from QCD jets, as we can see from its AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27776bf3",
   "metadata": {},
   "source": [
    "(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e325af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Repeat everything for CNN\n",
    "class CNN_Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_Autoencoder, self).__init__()\n",
    "\n",
    "        self.conv1_enc = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_enc = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_enc = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv_trans1_dec = nn.ConvTranspose2d(32, 32, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, \n",
    "                               padding=1)\n",
    "        self.conv_trans2_dec = nn.ConvTranspose2d(32, 32, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, \n",
    "                               padding=1)\n",
    "        self.conv_trans3_dec = nn.ConvTranspose2d(32, 1, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, \n",
    "                               padding=1)\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        self.upsample = nn.Upsample(scale_factor=(2,2))\n",
    "        self.pool_enc = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # ENCODER\n",
    "        x = self.conv1_enc(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.pool_enc(x)\n",
    "        # x = self.pool_enc(x)\n",
    "        x = self.conv2_enc(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.pool_enc(x)\n",
    "        # x = self.pool_enc(x)\n",
    "        x = self.conv3_enc(x)\n",
    "\n",
    "\n",
    "        # DECODER\n",
    "        x = self.upsample(x)\n",
    "        # x = self.upsample(x)\n",
    "        x = self.conv_trans1_dec(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        # x = self.upsample(x)\n",
    "        x = self.conv_trans2_dec(x)\n",
    "        x = self.act(x)\n",
    "\n",
    "        x = self.conv_trans3_dec(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706e1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the QCD training data\n",
    "qcd_train = z_train[ np.where( y_train == 0 ) ]\n",
    "qcd_train_tensor = torch.tensor( qcd_train.astype( np.float32 ) )\n",
    "\n",
    "\n",
    "# Generate the QCD training labels (we will not use these but we need them for the dataloader)\n",
    "qcd_train_labels = y_train[ np.where( y_train == 0 ) ]\n",
    "qcd_train_labels = torch.Tensor( qcd_train_labels.astype( np.float32 ) ).unsqueeze( -1 )\n",
    "\n",
    "\n",
    "# Building the dataloader\n",
    "train_dataset = dataset_manipulator( qcd_train_tensor, qcd_train_labels )\n",
    "trn_dataloader = torch.utils.data.DataLoader( train_dataset, batch_size=30, shuffle=True )\n",
    "\n",
    "model = CNN_Autoencoder()\n",
    "epochs = 10\n",
    "losses = train_autoencoder( model, trn_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( np.linspace(0,epochs,len(losses)),losses, c=\"darkcyan\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jets = torch.tensor(z_test.astype(np.float32))\n",
    "\n",
    "\n",
    "test_jets_labels = torch.Tensor( y_test.astype(np.float32) ).unsqueeze( -1 )\n",
    "\n",
    "\n",
    "test_dataset = dataset_manipulator( test_jets, test_jets_labels )\n",
    "tst_dataloader = torch.utils.data.DataLoader( test_dataset, batch_size=30, shuffle=False )\n",
    "\n",
    "losses = test_autoencoder(model, tst_dataloader)\n",
    "plt.plot(losses, c=\"darkcyan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa89f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_jets_val = torch.tensor(z_val.astype(np.float32))\n",
    "top_jets_original = z_val[ np.where(y_val==1) ]\n",
    "qcd_jets_original = z_val[ np.where(y_val==0) ]\n",
    "\n",
    "prova = model(top_jets_val)\n",
    "prova = prova.detach().numpy()\n",
    "\n",
    "reconstructed_top_jets = prova[ np.where(y_val==1) ]\n",
    "reconstructed_qcd_jets = prova[ np.where(y_val==0) ]\n",
    "\n",
    "fig, axs = plt.subplots( 4, 4, figsize=(18,18) )\n",
    "\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow( top_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[0, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[0, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[0, i].set_title(f\"Original TOP jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[1, i].imshow( reconstructed_top_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[1, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[1, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[1, i].set_title(\"Corresponding reconstructed TOP jet\", fontsize=10)\n",
    "\n",
    "    axs[2, i].imshow( qcd_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[2, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[2, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[2, i].set_title(f\"Original QCD jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[3, i].imshow( reconstructed_qcd_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[3, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[3, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[3, i].set_title(\"Corresponding reconstructed QCD jet\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e60988",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( 1, 2, figsize=(9, 5) )\n",
    "axs[0].imshow(z_val.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[0].set_xlabel( \"$\\eta$\" )\n",
    "axs[0].set_ylabel( \"$\\phi$\" )\n",
    "axs[0].set_title(f\"Original dataset average distribution\", fontsize=10)\n",
    "\n",
    "axs[1].imshow(prova.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[1].set_xlabel( \"$\\eta$\" )\n",
    "axs[1].set_ylabel( \"$\\phi$\" )\n",
    "axs[1].set_title(f\"Reconstructed dataset average distribution\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize pixel-wise MSE, plot ROC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "qcd_mse = []\n",
    "top_mse = []\n",
    "\n",
    "for i in range(qcd_jets_original.shape[0]):\n",
    "    qcd_mse.append(mean_squared_error(qcd_jets_original[i][0], reconstructed_qcd_jets[i][0]))\n",
    "for i in range(top_jets_original.shape[0]):    \n",
    "    top_mse.append(mean_squared_error(top_jets_original[i][0], reconstructed_top_jets[i][0]))\n",
    "\n",
    "average_qcd_mse = np.mean(qcd_mse)\n",
    "average_top_mse = np.mean(top_mse)\n",
    "\n",
    "plt.scatter(range(4), qcd_mse[0:4], marker=\".\", c=\"darkcyan\", label=\"QCD MSE\")\n",
    "plt.scatter(range(5, 9), top_mse[0:4], marker=\".\", c=\"skyblue\", label=\"TOP MSE\")\n",
    "\n",
    "plt.axhline(y=average_qcd_mse, color=\"darkcyan\", linestyle=\"--\", label=\"avg QCD MSE\")\n",
    "plt.axhline(y=average_top_mse, color=\"skyblue\", linestyle=\"--\", label=\"avg TOP MSE\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Jet\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_mse = np.array(qcd_mse)\n",
    "top_mse = np.array(top_mse)\n",
    "jets_mse = np.concatenate((qcd_mse,top_mse), axis=None)\n",
    "jets_mse.size\n",
    "\n",
    "label_jets = []\n",
    "\n",
    "for i in range(qcd_mse.size):\n",
    "    label_jets.append(0)\n",
    "\n",
    "for i in range(top_mse.size):\n",
    "    label_jets.append(1)\n",
    "\n",
    "label_jets = np.array(label_jets)\n",
    "\n",
    "\n",
    "fpr, tpr, th = roc_curve(label_jets,jets_mse)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('Specificity (False Positive) [%]')\n",
    "plt.ylabel('Sensitivity (True Positive) [%]')\n",
    "plt.grid()\n",
    "plt.plot(fpr*100, tpr*100, c=\"darkcyan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78637689",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad65d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Repeat everything for autoencoder trained on top jets\n",
    "# You can either use a MLP or a CNN\n",
    "\n",
    "# Preprocess the top jets training data\n",
    "top_train = z_train[ np.where( y_train == 1 ) ]\n",
    "top_train_tensor = torch.tensor( top_train.astype( np.float32 ) )\n",
    "\n",
    "\n",
    "# Generate the top training labels (we will not use these but we need them for the dataloader)\n",
    "top_train_labels = y_train[ np.where( y_train == 1 ) ]\n",
    "top_train_labels = torch.Tensor( top_train_labels.astype( np.float32 ) ).unsqueeze( -1 )\n",
    "\n",
    "\n",
    "# Building the dataloader\n",
    "train_dataset = dataset_manipulator( top_train_tensor, top_train_labels )\n",
    "trn_dataloader = torch.utils.data.DataLoader( train_dataset, batch_size=30, shuffle=True )\n",
    "\n",
    "model = Autoencoder(20)\n",
    "epochs = 10\n",
    "losses = train_autoencoder( model, trn_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot( np.linspace(0,epochs,len(losses)),losses, c=\"darkcyan\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c6fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jets = torch.tensor(z_test.astype(np.float32))\n",
    "\n",
    "test_jets_labels = torch.Tensor( y_test.astype(np.float32) ).unsqueeze( -1 )\n",
    "\n",
    "test_dataset = dataset_manipulator( test_jets, test_jets_labels )\n",
    "tst_dataloader = torch.utils.data.DataLoader( test_dataset, batch_size=30, shuffle=False )\n",
    "\n",
    "losses = test_autoencoder(model, tst_dataloader)\n",
    "plt.plot(losses, c=\"darkcyan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e78e03",
   "metadata": {},
   "source": [
    "Letting the QCD jets be the anomaly makes the performance of the autoencoder model slightly worse. We expect worse reconstructed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deab37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_jets_val = torch.tensor(z_val.astype(np.float32))\n",
    "top_jets_original = z_val[ np.where(y_val==1) ]\n",
    "qcd_jets_original = z_val[ np.where(y_val==0) ]\n",
    "\n",
    "pred = model(top_jets_val)\n",
    "pred = pred.detach().numpy()\n",
    "\n",
    "reconstructed_top_jets = pred[ np.where(y_val==1) ]\n",
    "reconstructed_qcd_jets = pred[ np.where(y_val==0) ]\n",
    "\n",
    "fig, axs = plt.subplots( 4, 4, figsize=(18,18) )\n",
    "\n",
    "for i in range(4):\n",
    "    axs[0, i].imshow( top_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[0, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[0, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[0, i].set_title(f\"Original TOP jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[1, i].imshow( reconstructed_top_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[1, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[1, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[1, i].set_title(\"Corresponding reconstructed TOP jet\", fontsize=10)\n",
    "\n",
    "    axs[2, i].imshow( qcd_jets_original[i][0], cmap=\"twilight\" )\n",
    "    axs[2, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[2, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[2, i].set_title(f\"Original QCD jet {i}\", fontsize=10)\n",
    "\n",
    "    axs[3, i].imshow( reconstructed_qcd_jets[i][0], cmap=\"twilight\" )\n",
    "    axs[3, i].set_xlabel( \"$\\eta$\" )\n",
    "    axs[3, i].set_ylabel( \"$\\phi$\" )\n",
    "    axs[3, i].set_title(\"Corresponding reconstructed QCD jet\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbc40d2",
   "metadata": {},
   "source": [
    "The quality of the results is comparable with the previos setup. This model is able to show more features of the top jets since their kernels are more clear, but we can see how the amount of noise is higly increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a45f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots( 1, 2, figsize=(9, 5) )\n",
    "axs[0].imshow(z_val.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[0].set_xlabel( \"$\\eta$\" )\n",
    "axs[0].set_ylabel( \"$\\phi$\" )\n",
    "axs[0].set_title(f\"Original dataset average distribution\", fontsize=10)\n",
    "\n",
    "axs[1].imshow(pred.mean(0)[0,...], cmap=\"twilight\")\n",
    "axs[1].set_xlabel( \"$\\eta$\" )\n",
    "axs[1].set_ylabel( \"$\\phi$\" )\n",
    "axs[1].set_title(f\"Reconstructed dataset average distribution\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b399b6",
   "metadata": {},
   "source": [
    "The average distribution of the reconstructed images also suffers from noise, resulting in an overall worse reconstruction respect to the previous setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38589a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize pixel-wise MSE, plot ROC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "qcd_mse = []\n",
    "top_mse = []\n",
    "\n",
    "for i in range(qcd_jets_original.shape[0]):\n",
    "    qcd_mse.append(mean_squared_error(qcd_jets_original[i][0], reconstructed_qcd_jets[i][0]))\n",
    "for i in range(top_jets_original.shape[0]):    \n",
    "    top_mse.append(mean_squared_error(top_jets_original[i][0], reconstructed_top_jets[i][0]))\n",
    "\n",
    "average_qcd_mse = np.mean(qcd_mse)\n",
    "average_top_mse = np.mean(top_mse)\n",
    "\n",
    "plt.scatter(range(4), qcd_mse[0:4], marker=\".\", c=\"red\", label=\"QCD MSE\")\n",
    "plt.scatter(range(5, 9), top_mse[0:4], marker=\".\", c=\"blue\", label=\"TOP MSE\")\n",
    "\n",
    "plt.axhline(y=average_qcd_mse, color=\"red\", linestyle=\"--\", label=\"avg QCD MSE\")\n",
    "plt.axhline(y=average_top_mse, color=\"blue\", linestyle=\"--\", label=\"avg TOP MSE\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Jet\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb71bf",
   "metadata": {},
   "source": [
    "As expected the average value of MSE for TOP jets is lower than for QCD jets, but the results are worse compared to the previous setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06192a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "qcd_mse = np.array(qcd_mse)\n",
    "top_mse = np.array(top_mse)\n",
    "jets_mse = np.concatenate((qcd_mse,top_mse), axis=None)\n",
    "jets_mse.size\n",
    "\n",
    "label_jets = []\n",
    "\n",
    "for i in range(qcd_mse.size):\n",
    "    label_jets.append(0)\n",
    "\n",
    "for i in range(top_mse.size):\n",
    "    label_jets.append(1)\n",
    "\n",
    "label_jets = np.array(label_jets)\n",
    "\n",
    "\n",
    "rnd_class = np.linspace(0, 1, 100)\n",
    "fpr2, tpr2, th2 = roc_curve(label_jets,jets_mse)\n",
    "auc_score2 = roc_auc_score(label_jets,jets_mse)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('Specificity (False Positive) [%]')\n",
    "plt.ylabel('Sensitivity (True Positive) [%]')\n",
    "plt.grid()\n",
    "plt.plot(fpr2, tpr2, label=f'AUC (tr. on TOP) = {auc_score2:.2f}' )\n",
    "plt.plot(fpr, tpr, label=f'AUC (tr. on QCD)= {auc_score:.2f}' )\n",
    "plt.plot(rnd_class, rnd_class, '--', label='Rnd classifier')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b2306c",
   "metadata": {},
   "source": [
    "A comparison between the ROC curve of the test statistic obtained training the Autoencoder on QCD and TOP jets. The second one is clearly much worse, as we can deduce from its AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846aa56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d77c1728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cddda5fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9839cf8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f3e7bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "246ca070",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf311299",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe62a7e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a887a18",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
